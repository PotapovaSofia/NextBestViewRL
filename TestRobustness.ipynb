{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import trimesh\n",
    "import math\n",
    "import k3d\n",
    "from time import sleep\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from geometry.model import Model, combine_observations, get_mesh\n",
    "from geometry.utils.visualisation import illustrate_points, illustrate_mesh\n",
    "from rl.environment import *\n",
    "\n",
    "from geometry.voxel_grid import *\n",
    "builder = VoxelGridBuilder(32)\n",
    "\n",
    "\n",
    "# !conda install -c conda-forge pyembree\n",
    "# !conda install -c conda-forge igl\n",
    "# !pip install Cython\n",
    "# !pip install gym\n",
    "# jupyter nbextension install --py --sys-prefix k3d\n",
    "# jupyter nbextension enable --py --sys-prefix k3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(gym.Env):\n",
    "    def __init__(self,\n",
    "                 models_path=None,\n",
    "                 model_path=None,\n",
    "                 number_of_view_points=100,\n",
    "                 similarity_threshold=0.95,\n",
    "                 image_size=512,\n",
    "                 illustrate=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.models_path = models_path\n",
    "        self.number_of_view_points = number_of_view_points\n",
    "        self.image_size = image_size\n",
    "        self.illustrate = illustrate\n",
    "\n",
    "        self.action_space = spaces.Discrete(number_of_view_points)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'depth_map': spaces.Box(-np.inf, np.inf, (image_size, image_size), dtype=np.float32),\n",
    "        })\n",
    "\n",
    "        self._similarity_threshold = similarity_threshold\n",
    "        self._reconstruction_depth = 10\n",
    "\n",
    "        self.model = None\n",
    "        self.plot = None\n",
    "\n",
    "    def reset(self, init_action=None):\n",
    "        \"\"\"\n",
    "        Reset the environment for new episode.\n",
    "        Randomly (or not) generate CAD model for this episode.\n",
    "        \"\"\"\n",
    "        if self.model_path is not None:\n",
    "            model_path = self.model_path\n",
    "        elif self.models_path is not None:\n",
    "            model_path = os.path.join(self.models_path,\n",
    "                                      random.sample(os.listdir(self.models_path), 1)[0])\n",
    "        self.model = Model(model_path, resolution_image=self.image_size)\n",
    "        self.model.generate_view_points(self.number_of_view_points)\n",
    "        \n",
    "        if self.illustrate:\n",
    "            self.model.illustrate().display()\n",
    "\n",
    "            self.plot = k3d.plot()\n",
    "            self.plot.display()\n",
    "        \n",
    "        if init_action is None:\n",
    "            init_action = self.action_space.sample()\n",
    "        observation = self.model.get_observation(init_action)\n",
    "        return observation, init_action\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Get new observation from current position (action), count step reward, decide whether to stop.\n",
    "        Args:\n",
    "            action: int\n",
    "        return: \n",
    "            next_state: List[List[List[int, int, int]]]\n",
    "            reward: float\n",
    "            done: bool\n",
    "            info: Tuple\n",
    "        \"\"\"\n",
    "        assert self.action_space.contains(action)\n",
    "        \n",
    "        view_point = self.model.view_points[action]\n",
    "        new_view_point = add_noise_to_vp(view_point, self.model)\n",
    "        observation = self.model.get_observation_from_point(view_point)\n",
    "\n",
    "        reward = self.step_reward(observation)\n",
    "        done = reward >= self._similarity_threshold\n",
    "\n",
    "        return observation, reward, done, {}\n",
    "    \n",
    "    def render(self, action, observation, plot=None):\n",
    "        if plot is None:\n",
    "            plot = self.plot\n",
    "            \n",
    "        plot = illustrate_points(\n",
    "           [self.model.get_point(action)], size=0.5, plot=plot)\n",
    "        \n",
    "        plot = observation.illustrate(plot, size=0.03)\n",
    "        return plot\n",
    "    \n",
    "    def step_reward(self, observation):\n",
    "        return self.model.observation_similarity(observation)\n",
    "    \n",
    "        if self.illustrate:\n",
    "            illustrate_mesh(vertices, faces).display()\n",
    "        return reward\n",
    "        \n",
    "    def _get_mesh(self, observation):\n",
    "        faces, vertices = poisson_reconstruction(observation.points,\n",
    "                                                 observation.normals,\n",
    "                                                 depth=self._reconstruction_depth)\n",
    "        return vertices, faces\n",
    "\n",
    "    def final_reward(self, observation):\n",
    "        vertices, faces = self._get_mesh(observation)\n",
    "        reward = self.model.surface_similarity(vertices, faces)\n",
    "        return reward\n",
    "\n",
    "\n",
    "\n",
    "def create_env(model_path=None, number_of_view_points=100):    \n",
    "    env = Environment(model_path=model_path,\n",
    "                      image_size=1024,\n",
    "                      number_of_view_points=number_of_view_points)\n",
    "\n",
    "    env = MeshReconstructionWrapper(env, reconstruction_depth=8, final_depth=10, scale_factor=8,\n",
    "                                    do_step_reconstruction=True)\n",
    "    env = VoxelGridWrapper(env, grid_size=32)\n",
    "    env = CombiningObservationsWrapper(env)\n",
    "    env = VoxelWrapper(env, occlusion_reward=True)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometry.model import ViewPoint\n",
    "\n",
    "def add_noise_to_vp(view_point, model):\n",
    "    # YOUR CODE IS HERE\n",
    "    # use model.bounds / 32\n",
    "    point = view_point.point\n",
    "    phi = view_point.phi\n",
    "    theta = view_point.theta\n",
    "    return ViewPoint(point, phi, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/00070090_73b2f35a88394199b6fd1ab8_003.obj\n",
      "View points:  [63, 29, 54]\n",
      "Voxels after NBV:  6430\n",
      "Hausdorff:  0.3345277645033892\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "models_paths = [\n",
    "    \"./data/00070090_73b2f35a88394199b6fd1ab8_003.obj\",\n",
    "    \"./data/00060056_5f75fa75edda41c2a78510a7_000.obj\",\n",
    "    \"./data/val/00010116_a35af5bb7a7a42fe9539f3b7_008.obj\",\n",
    "    \"./data/val/00010152_13f1e6a043494993aa8494b7_000.obj\",\n",
    "    \"./data/val/00010155_ccef4063b69f428e91b498c9_000.obj\",\n",
    "    \"./data/val/00010159_ccef4063b69f428e91b498c9_004.obj\",\n",
    "    \"./data/val/00010169_859b5c4a8376437fa24c285b_001.obj\",\n",
    "    \"./data/val/00010174_30f2ce809de74ac596f8a219_000.obj\",\n",
    "    \"./data/val/00020151_b27a1602d1d44a3d89140ce4_051.obj\",\n",
    "    \"./data/val/00020228_f7a8b12633374114bcbd6244_000.obj\"]\n",
    "\n",
    "\n",
    "view_point_idxs = [\n",
    "    [63, 29, 54],\n",
    "    [35, 65, 37],\n",
    "    [8, 85],\n",
    "    [93, 18],\n",
    "    [94, 1, 93],\n",
    "    [3, 88],\n",
    "    [15, 79, 77],\n",
    "    [26, 77],\n",
    "    [0, 93, 94, 38],\n",
    "    [1, 68]\n",
    "]\n",
    "\n",
    "for model_path, vp_idxs in zip(models_paths, view_point_idxs):\n",
    "    \n",
    "    env = create_env(model_path, number_of_view_points=100)\n",
    "\n",
    "    state, action = env.reset(init_action=vp_idxs[0])\n",
    "    states = [state]\n",
    "    model = env.model\n",
    "    \n",
    "    for action in vp_idxs[1:]:\n",
    "        state, reward, done, info = env.step(action)\n",
    "        states.append(state)\n",
    "\n",
    "    voxels_after_nbv = np.count_nonzero(states[-1] == 2)\n",
    "    \n",
    "    combined_observation = None\n",
    "    for view_point_idx in vp_idxs:\n",
    "        view_point = model.view_points[view_point_idx]\n",
    "        new_view_point = add_noise_to_vp(view_point, model)\n",
    "        observation = model.get_observation_from_point(view_point)\n",
    "\n",
    "        if combined_observation is None:\n",
    "            combined_observation = observation\n",
    "        else:\n",
    "            combined_observation += observation\n",
    "\n",
    "    reconstructed_vertices, reconstructed_faces = get_mesh(combined_observation)\n",
    "    loss = model.surface_similarity(reconstructed_vertices, reconstructed_faces)\n",
    "\n",
    "    print(model_path)\n",
    "    print(\"View points: \", vp_idxs)\n",
    "    print(\"Voxels after NBV: \", voxels_after_nbv)\n",
    "    print(\"Hausdorff: \", loss)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac499a2c64840a7ae31c4390e99c459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera_animation=[], camer…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL_PATH = \"./data/00070090_73b2f35a88394199b6fd1ab8_003.obj\"\n",
    "\n",
    "# model = Model(model_path=MODEL_PATH)\n",
    "# model.generate_view_points(10)\n",
    "\n",
    "model.illustrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bfc447f4e64babb3cc533a7174bc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera_animation=[], camer…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "illustrate_mesh(reconstructed_vertices, reconstructed_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b907a2a45247c39badaae69fb6cf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera_animation=[], camer…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bounds = np.array([np.min(reconstructed_vertices, axis=0), np.max(reconstructed_vertices, axis=0)])\n",
    "mesh_grid_rec = builder.build(reconstructed_vertices, bounds)\n",
    "\n",
    "\n",
    "\n",
    "plot = k3d.plot()\n",
    "plt_voxels = k3d.voxels(mesh_grid_rec.grid() * 3)\n",
    "plot += plt_voxels\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef58018eb9e4137a2199300a80a83dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render(action, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63, 29, 54]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc85325605845aa953f87da8bcb6574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera_animation=[], camer…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = illustrate_voxels(states[-1] * 3)\n",
    "illustrate_points(vp_idxs[:1], size=5, plot=plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd9357a95e44c6da6249d55243a9013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera_animation=[], camer…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.model.illustrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
