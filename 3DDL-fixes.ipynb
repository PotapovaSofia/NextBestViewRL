{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import trimesh\n",
    "import k3d\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from trimesh.ray.ray_pyembree import RayMeshIntersector\n",
    "from pypoisson import poisson_reconstruction\n",
    "\n",
    "from igl import hausdorff\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from torch import FloatTensor\n",
    "\n",
    "from utils.view import from_pose\n",
    "# from utils.sampling import get_config\n",
    "\n",
    "# !conda install -c conda-forge pyembree\n",
    "# !conda install -c conda-forge igl\n",
    "# !pip install Cython\n",
    "# !pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_points(points, plot=None, size=0.1):\n",
    "    if plot is None:\n",
    "        plot = k3d.plot(name='points')\n",
    "    plt_points = k3d.points(positions=points, point_size=size)\n",
    "    plot += plt_points\n",
    "    plt_points.shader='3d'\n",
    "    return plot\n",
    "\n",
    "def illustrate_mesh(vertices, faces, plot=None):\n",
    "    if plot is None:\n",
    "        plot = k3d.plot()\n",
    "        \n",
    "    plt_surface = k3d.mesh(vertices, faces,\n",
    "                           color_map = k3d.colormaps.basic_color_maps.Blues,\n",
    "                           attribute=vertices[:, 2])\n",
    "\n",
    "    plot += plt_surface\n",
    "    return plot\n",
    "\n",
    "\n",
    "def transform_mesh(mesh, rotation, translation=None, reverse=False):\n",
    "    # rotation = from_pose([x, y, z], [0, 0, 0]) \n",
    "    mesh_ = mesh.copy()\n",
    "    if reverse:\n",
    "        if translation is not None:\n",
    "            mesh_.apply_translation(-translation)\n",
    "        mesh_.apply_transform(rotation.T)\n",
    "    else:\n",
    "        mesh_.apply_transform(rotation)\n",
    "        if translation is not None:\n",
    "            mesh_.apply_translation(translation)\n",
    "\n",
    "    return mesh_\n",
    "\n",
    "\n",
    "def transform_points(points, rotation, translation=None, reverse=False):\n",
    "    if translation is None:\n",
    "        translation = np.zeros((3))\n",
    "    rotation = rotation[:3, :3]\n",
    "    \n",
    "    if reverse:\n",
    "        return (points - translation).dot(rotation)\n",
    "    return points.dot(rotation.T) + translation\n",
    "\n",
    "\n",
    "def generate_sunflower_sphere_points(num_points=100):\n",
    "    indices = np.arange(0, num_points, dtype=float) + 0.5\n",
    "\n",
    "    phi = np.arccos(1 - 2 * indices / num_points)\n",
    "    theta = np.pi * (1 + 5 ** 0.5) * indices\n",
    "\n",
    "    x, y, z = np.cos(theta) * np.sin(phi), np.sin(theta) * np.sin(phi), np.cos(phi)\n",
    "    points = np.vstack([x, y, z]).T\n",
    "    return points, phi, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaycastingImaging:\n",
    "    def __init__(self, resolution_image=512, resolution_3d=0.02, projection=\"ortho\"):\n",
    "        self.resolution_image = resolution_image\n",
    "        self.resolution_3d = resolution_3d\n",
    "        self.projection = projection\n",
    "        # self.fov = [115, 85, 80]\n",
    "\n",
    "        self.rays_screen_coords, self.rays_origins, self.rays_directions = None, None, None\n",
    "\n",
    "        \n",
    "    def prepare(self, scanning_radius):\n",
    "        # scanning radius is determined from the mesh extent\n",
    "        self.rays_screen_coords, self.rays_origins, self.rays_directions = generate_rays(\n",
    "            self.resolution_image, self.resolution_3d, radius=scanning_radius)\n",
    "\n",
    "    def get_image(self, mesh): #, features):\n",
    "        if any(value is None for value in [self.rays_screen_coords, self.rays_origins, self.rays_directions]):\n",
    "            raise DataGenerationException('Raycasting was not prepared')\n",
    "\n",
    "        # get a point cloud with corresponding indexes\n",
    "        mesh_face_indexes, ray_indexes, points = ray_cast_mesh(\n",
    "            mesh, self.rays_origins, self.rays_directions)\n",
    "\n",
    "        # extract normals\n",
    "        normals = mesh.face_normals[mesh_face_indexes]\n",
    "\n",
    "        # compute indexes of faces and vertices in the original mesh\n",
    "        # hit_surfaces_face_indexes = []\n",
    "        # for idx, surface in enumerate(features['surfaces']):\n",
    "        #     surface_face_indexes = np.array(surface['face_indices'])\n",
    "        #     if np.any(np.isin(surface_face_indexes, mesh_face_indexes, assume_unique=True)):\n",
    "        #         hit_surfaces_face_indexes.extend(surface_face_indexes)\n",
    "        # mesh_face_indexes = np.unique(hit_surfaces_face_indexes)\n",
    "        mesh_face_indexes = np.unique(mesh_face_indexes)\n",
    "        mesh_vertex_indexes = np.unique(mesh.faces[mesh_face_indexes])\n",
    "        return ray_indexes, points, normals, mesh_vertex_indexes, mesh_face_indexes\n",
    "\n",
    "        # assemble mesh fragment into a submesh\n",
    "        # nbhood = reindex_zerobased(mesh, mesh_vertex_indexes, mesh_face_indexes)\n",
    "        # return ray_indexes, points, normals, nbhood, mesh_vertex_indexes, mesh_face_indexes\n",
    "\n",
    "    def points_to_image(self, points, ray_indexes, assign_channels=None):\n",
    "        xy_to_ij = self.rays_screen_coords[ray_indexes]\n",
    "        # note that `points` can have many data dimensions\n",
    "        if None is assign_channels:\n",
    "            assign_channels = [2]\n",
    "        data_channels = len(assign_channels)\n",
    "        image = np.zeros((self.resolution_image, self.resolution_image, data_channels))\n",
    "        image[xy_to_ij[:, 0], xy_to_ij[:, 1]] = points[:, assign_channels]\n",
    "        return image.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trimesh.ray.ray_pyembree import RayMeshIntersector\n",
    "\n",
    "\n",
    "def generate_rays(image_resolution, resolution_3d, radius=1.0):\n",
    "    \"\"\"Creates an array of rays and ray directions used for mesh raycasting.\n",
    "    :param image_resolution: image resolution in pixels\n",
    "    :type image_resolution: int or tuple of ints\n",
    "    :param resolution_3d: pixel 3d resolution in mm/pixel\n",
    "    :type resolution_3d: float\n",
    "    :param radius: Z coordinate for the rays origins\n",
    "    :type resolution_3d: float\n",
    "    :return:\n",
    "        rays_screen_coords:     (W * H, 2): screen coordinates for the rays\n",
    "        rays_origins:           (W * H, 3): world coordinates for rays origins\n",
    "        ray_directions:         (W * H, 3): unit norm vectors pointing in directions of the rays\n",
    "    \"\"\"\n",
    "    if isinstance(image_resolution, tuple):\n",
    "        assert len(image_resolution) == 2\n",
    "    else:\n",
    "        image_resolution = (image_resolution, image_resolution)\n",
    "    image_width, image_height = image_resolution\n",
    "\n",
    "    # generate an array of screen coordinates for the rays\n",
    "    # (rays are placed at locations [i, j] in the image)\n",
    "    rays_screen_coords = np.mgrid[0:image_height, 0:image_width].reshape(\n",
    "        2, image_height * image_width).T    # [h, w, 2]\n",
    "\n",
    "    # place rays physically in locations determined by screen coordinates,\n",
    "    # then shift so that camera origin is in the midpoint in the image,\n",
    "    # and linearly stretch so each pixel takes exactly resolution_3d space\n",
    "    screen_aspect_ratio = image_width / image_height\n",
    "    rays_origins = (rays_screen_coords / np.array([[image_height, image_width]]))   # [h, w, 2], in [0, 1]\n",
    "    factor = image_height / 2 * resolution_3d\n",
    "    rays_origins[:, 0] = (-2 * rays_origins[:, 0] + 1) * factor  # to [-1, 1] + aspect transform\n",
    "    rays_origins[:, 1] = (-2 * rays_origins[:, 1] + 1) * factor * screen_aspect_ratio\n",
    "    rays_origins = np.concatenate([\n",
    "        rays_origins,\n",
    "        radius + np.zeros_like(rays_origins[:, [0]])\n",
    "    ], axis=1)  # [h, w, 3]\n",
    "\n",
    "    # ray directions are always facing towards Z axis\n",
    "    ray_directions = np.tile(np.array([0, 0, -1]), (rays_origins.shape[0], 1))\n",
    "\n",
    "    return rays_screen_coords, rays_origins, ray_directions\n",
    "\n",
    "\n",
    "def ray_cast_mesh(mesh, rays_origins, ray_directions):\n",
    "    intersector = RayMeshIntersector(mesh)\n",
    "    index_triangles, index_ray, point_cloud = intersector.intersects_id(\n",
    "        ray_origins=rays_origins, ray_directions=ray_directions,\n",
    "        multiple_hits=False, return_locations=True)\n",
    "    return index_triangles, index_ray, point_cloud\n",
    "\n",
    "\n",
    "def make_noise(points, normals, scale=0.0, z_direction=None, **kwargs):\n",
    "    assert z_direction is not None\n",
    "    noise = np.random.normal(size=(len(points), 1), scale=scale) * z_direction\n",
    "    noisy_points = points + noise * z_direction\n",
    "    return noisy_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.matrix_torch import (create_rotation_matrix_x, create_rotation_matrix_y, create_rotation_matrix_z, create_translation_matrix)\n",
    "\n",
    "\n",
    "class ViewPoint:\n",
    "    def __init__(self, point, phi, theta):\n",
    "        self.point = point\n",
    "        self.phi = phi\n",
    "        self.theta = theta\n",
    "        \n",
    "    def get_transform_matrix(self):\n",
    "        rotation = torch.mm(create_rotation_matrix_y(-self.phi),\n",
    "                            create_rotation_matrix_z(-self.theta))\n",
    "        \n",
    "        translation = create_translation_matrix(0, 0, 0)\n",
    "        transform = torch.mm(rotation, translation)\n",
    "        return transform.t()\n",
    "        \n",
    "\n",
    "class Observation:\n",
    "    def __init__(self, points, normals, vertex_indexes, face_indexes, depth_map, normals_image):\n",
    "        self.points = points\n",
    "        self.normals = normals\n",
    "        self.vertex_indexes = vertex_indexes\n",
    "        self.face_indexes = face_indexes\n",
    "        \n",
    "        if len(depth_map.shape) == 2:\n",
    "            self.depth_map = np.expand_dims(depth_map, 0)\n",
    "            self.normals_image = np.expand_dims(normals_image, 0)\n",
    "        else:\n",
    "            self.depth_map = depth_map\n",
    "            self.normals_image = normals_image\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.face_indexes.shape[0]\n",
    "    \n",
    "    \n",
    "    def transform(self, transform):\n",
    "        self.points = transform_points(self.points, transform)\n",
    "        self.normals = transform_points(self.normals, transform,\n",
    "                                        translation=None)\n",
    "        \n",
    "        \n",
    "    def __add__(self, other):\n",
    "        points = np.concatenate([self.points, other.points])\n",
    "        normals = np.concatenate([self.normals, other.normals])\n",
    "        \n",
    "        vertex_indexes = np.unique(np.concatenate([self.vertex_indexes,\n",
    "                                                   other.vertex_indexes]))\n",
    "        face_indexes = np.unique(np.concatenate([self.face_indexes,\n",
    "                                                 other.face_indexes]))\n",
    "        \n",
    "        depth_map = np.concatenate([self.depth_map, other.depth_map])\n",
    "        normals_image = np.concatenate([self.normals_image, other.normals_image])\n",
    "        \n",
    "        return Observation(points, normals, vertex_indexes, face_indexes, depth_map, normals_image)\n",
    "        \n",
    "        \n",
    "    def illustrate(self, plot=None, size=0.05):\n",
    "        return illustrate_points(self.points, plot=plot, size=size)\n",
    "    \n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, model_path):\n",
    "        self.mesh = self.load_mesh(model_path)\n",
    "        self.transform = np.eye(4)\n",
    "        \n",
    "        self.raycaster = self.prepare_raycaster()\n",
    "        \n",
    "        self.view_points = []\n",
    "    \n",
    "    \n",
    "    def load_mesh(self, mesh_path, shape_fabrication_extent=10.0):\n",
    "        mesh = trimesh.load_mesh(mesh_path)\n",
    "        mesh_extent = np.max(mesh.bounding_box.extents)\n",
    "        mesh = mesh.apply_scale(shape_fabrication_extent / mesh_extent)\n",
    "        # TODO compute lengths of curves + quantiles\n",
    "        mesh = mesh.apply_translation(-mesh.vertices.mean(axis=0))\n",
    "        return mesh\n",
    "    \n",
    "    def prepare_raycaster(self):\n",
    "        raycaster = RaycastingImaging()\n",
    "        raycaster.prepare(scanning_radius=np.max(self.mesh.bounding_box.extents) + 1.0)\n",
    "        return raycaster\n",
    "    \n",
    "    def generate_view_points(self, num_points=100):\n",
    "        sphere_points, phis, thetas = generate_sunflower_sphere_points(num_points)\n",
    "\n",
    "        dists = self.mesh.vertices - self.mesh.center_mass\n",
    "        radius = np.abs(dists).max()\n",
    "        radius *= 1.20\n",
    "\n",
    "        sphere_points *= radius\n",
    "        sphere_points += self.mesh.center_mass\n",
    "\n",
    "        for point, phi, theta in zip(sphere_points, phis, thetas):\n",
    "            self.view_points.append(ViewPoint(point, phi, theta))\n",
    "            \n",
    "            \n",
    "    def get_point(self, view_point_idx):\n",
    "        return self.view_points[view_point_idx].point\n",
    "            \n",
    "\n",
    "    def illustrate(self):\n",
    "        plot = illustrate_mesh(self.mesh.vertices, self.mesh.faces)\n",
    "        plot = illustrate_points([vp.point for vp in self.view_points],\n",
    "                                 plot, size=0.1)\n",
    "        return plot\n",
    "\n",
    "\n",
    "    def rotate_to_view_point(self, view_point):\n",
    "        self.transform = view_point.get_transform_matrix()\n",
    "        self.mesh = transform_mesh(self.mesh, self.transform, reverse=True)\n",
    "        \n",
    "        \n",
    "    def rotate_to_origin(self):\n",
    "        self.mesh = transform_mesh(self.mesh, self.transform, reverse=False)\n",
    "        self.transform = np.eye(4)\n",
    "\n",
    "        \n",
    "    def raycast(self, visibility_eps = 1e-6):\n",
    "        \n",
    "        (ray_indexes,\n",
    "         points,\n",
    "         normals,\n",
    "         mesh_vertex_indexes,\n",
    "         mesh_face_indexes) = self.raycaster.get_image(self.mesh)\n",
    "        \n",
    "        noisy_points = make_noise(points, normals, z_direction=np.array([0., 0., -1.]))\n",
    "        depth_map = self.raycaster.points_to_image(noisy_points, ray_indexes)\n",
    "        normals_image = self.raycaster.points_to_image(normals, ray_indexes,\n",
    "                                                       assign_channels=[0, 1, 2])\n",
    "\n",
    "        observation = Observation(noisy_points,\n",
    "                                  normals,\n",
    "                                  mesh_vertex_indexes,\n",
    "                                  mesh_face_indexes,\n",
    "                                  depth_map,\n",
    "                                  normals_image)\n",
    "        return observation\n",
    "\n",
    "\n",
    "    def get_observation(self, view_point_idx):\n",
    "        view_point = self.view_points[view_point_idx]\n",
    "        self.rotate_to_view_point(view_point)\n",
    "        \n",
    "        observation = self.raycast()\n",
    "        observation.transform(self.transform)\n",
    "        \n",
    "        self.rotate_to_origin()\n",
    "        \n",
    "        return observation\n",
    "    \n",
    "    \n",
    "    def surface_similarity(self, reconstructed_vertices, reconstructed_faces):\n",
    "        return hausdorff(self.mesh.vertices,\n",
    "                         self.mesh.faces,\n",
    "                         reconstructed_vertices,\n",
    "                         reconstructed_faces.astype(np.int64))\n",
    "        \n",
    "\n",
    "    def observation_similarity(self, observation):\n",
    "        # TODO: We don't want to deal with GPU tensors right now, so simplify to this\n",
    "        # chamfer\n",
    "        # gt = FloatTensor(np.expand_dims(self.mesh.vertices, axis=0))\n",
    "        # pred = FloatTensor(np.expand_dims(observation.vertices, axis=0))\n",
    "        # return chamfer_distance(gt, pred)\n",
    "\n",
    "        # area ratio\n",
    "        return observation.face_indexes.shape[0] * 1.0 / self.mesh.faces.shape[0]\n",
    "\n",
    "    \n",
    "def get_mesh(observation):\n",
    "    faces, vertices = poisson_reconstruction(\n",
    "        observation.points, observation.normals, depth=10)\n",
    "    return vertices, faces\n",
    "\n",
    "\n",
    "def combine_observations(observations):\n",
    "    points = np.concatenate([observation.points for observation in observations])\n",
    "    normals = np.concatenate([observation.normals for observation in observations])\n",
    "\n",
    "    vertex_indexes = np.unique(np.concatenate([observation.vertex_indexes\n",
    "                                               for observation in observations]))\n",
    "    face_indexes = np.unique(np.concatenate([observation.face_indexes\n",
    "                                             for observation in observations]))\n",
    "\n",
    "    depth_map = np.concatenate([observation.depth_map for observation in observations])\n",
    "    normals_image = np.concatenate([observation.normals_image for observation in observations])\n",
    "\n",
    "    return Observation(points, normals, vertex_indexes, face_indexes, depth_map, normals_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636b94233d51419dab2d23543cfd7fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to load materials from: FinalBaseMesh.mtl\n",
      "specified material (default)  not loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059667802116076925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int32\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac725a9e5e34fb8b181744d87c136c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plot(antialias=3, axes=['x', 'y', 'z'], axes_helper=1.0, background_color=16777215, camera=[2, -3, 0.2, 0.0, 0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "NUM_POINTS = 10\n",
    "\n",
    "\n",
    "plot = k3d.plot(name='points')\n",
    "plot.display()\n",
    "\n",
    "model = Model(\"./data/Dude.obj\")\n",
    "model.generate_view_points(NUM_POINTS)\n",
    "\n",
    "observations = []\n",
    "for view_point_idx in range(NUM_POINTS):\n",
    "    observation = model.get_observation(view_point_idx)\n",
    "    \n",
    "    plot = observation.illustrate(plot, size=0.01)\n",
    "    plot = illustrate_points([model.get_point(view_point_idx)], size=1.0, plot=plot)\n",
    "    sleep(2)\n",
    "    \n",
    "    observations.append(observation)\n",
    "    \n",
    "combined_observation = combine_observations(observations)\n",
    "reconstructed_vertices, reconstructed_faces = get_mesh(combined_observation)\n",
    "\n",
    "loss = model.surface_similarity(reconstructed_vertices, reconstructed_faces)\n",
    "print(loss)\n",
    "\n",
    "illustrate_mesh(reconstructed_vertices, reconstructed_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "MAX_POINS_CNT = 100000\n",
    "VIEW_POINTS_CNT = 1000\n",
    "\n",
    "\n",
    "class EnvError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Environment(gym.Env):\n",
    "    def __init__(self, number_of_view_points=VIEW_POINTS_CNT):\n",
    "        super().__init__()\n",
    "\n",
    "        self.number_of_view_points = number_of_view_points\n",
    "\n",
    "        self.action_space = spaces.Discrete(number_of_view_points)\n",
    "        self.observation_space = spaces.Box(\n",
    "            -np.inf, np.inf, (MAX_POINS_CNT, 3), dtype=np.float32)\n",
    "\n",
    "        self._similarity_threshold = 1 - 1e-3\n",
    "        self._reconstruction_depth = 10\n",
    "\n",
    "        self.model = None\n",
    "        self.plot = None\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the environment for new episode.\n",
    "        Randomly (or not) generate CAD model for this episode.\n",
    "        \"\"\"\n",
    "        self.model = Model(\"./data/Dude.obj\")\n",
    "        self.model.generate_view_points(self.number_of_view_points)\n",
    "        \n",
    "        self.model.illustrate().display()\n",
    "        \n",
    "        init_state = self.action_space.sample()\n",
    "        observation = self.model.get_observation(init_state)\n",
    "        return observation\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Get new observation from current position (action), count step reward, decide whether to stop.\n",
    "        Args:\n",
    "            action: int\n",
    "        return: \n",
    "            next_state: List[List[List[int, int, int]]]\n",
    "            reward: float\n",
    "            done: bool\n",
    "            info: Tuple\n",
    "        \"\"\"\n",
    "        observation = self.model.get_observation(action)\n",
    "\n",
    "        reward = self.step_reward(observation)\n",
    "        done = reward >= self._similarity_threshold\n",
    "\n",
    "        return observation, reward, done, {}\n",
    "\n",
    "    \n",
    "    def render(self, action, observation, plot=None):\n",
    "        if plot is None:\n",
    "            plot = self.plot\n",
    "            \n",
    "        plot = illustrate_points(\n",
    "           [self.model.get_point(action)], size=0.5, plot=plot)\n",
    "        \n",
    "        plot = observation.illustrate(plot, size=0.01)\n",
    "        return plot\n",
    "    \n",
    "    \n",
    "    def step_reward(self, observation):\n",
    "        return self.model.observation_similarity(observation)\n",
    "    \n",
    "    \n",
    "    def final_reward(self, observation, illustrate=False):\n",
    "        vertices, faces = self._get_mesh(observation)\n",
    "        reward = self.model.surface_similarity(vertices, faces)\n",
    "        \n",
    "        if illustrate:\n",
    "            illustrate_mesh(vertices, faces).display()\n",
    "        return reward\n",
    "        \n",
    "        \n",
    "    def _get_mesh(self, observation):\n",
    "        faces, vertices = poisson_reconstruction(observation.points,\n",
    "                                                 observation.normals,\n",
    "                                                 depth=self._reconstruction_depth)\n",
    "        return vertices, faces\n",
    "\n",
    "\n",
    "    \n",
    "class CombiningObservationsWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # self.env = environment\n",
    "        \n",
    "        # self.action_space = env.action_space\n",
    "        # self.observation_space = env.observation_space\n",
    "        \n",
    "        self._similarity_threshold = 1 - 1e-2\n",
    "\n",
    "        self.combined_observation = None\n",
    "        self.plot = None\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        observation = self.env.reset()\n",
    "        self.combined_observation = observation\n",
    "        \n",
    "        self.plot = k3d.plot(name='wrapper')\n",
    "        self.plot.display()\n",
    "\n",
    "        \n",
    "    def step(self, action):\n",
    "        observation, reward, done, info = self.env.step(action)\n",
    "\n",
    "        self._combine_observations(observation)\n",
    "\n",
    "        combined_reward = self.env.step_reward(self.combined_observation)\n",
    "        done = done or combined_reward >= self._similarity_threshold\n",
    "        \n",
    "        new_reward = combined_reward - reward\n",
    "        print(\"Step reward: {:.6f}\".format(reward),\n",
    "              \"Comb reward: {:.6f}\".format(combined_reward),\n",
    "              \"new reward: {:.6f}\".format(new_reward),\n",
    "              \"Len observation: \", self.combined_observation.points.shape[0])\n",
    "        \n",
    "        return self.combined_observation, new_reward, done, info\n",
    "\n",
    "    \n",
    "    def render(self, action, observation):\n",
    "        self.plot = self.env.render(action, observation, self.plot)\n",
    "        \n",
    "    \n",
    "    def final_reward(self, illustrate=False):\n",
    "        return self.env.final_reward(self.combined_observation,\n",
    "                                     illustrate=illustrate)\n",
    "    \n",
    "\n",
    "    def _combine_observations(self, observation):\n",
    "        if self.combined_observation is None:\n",
    "            raise EnvError(\"Environment wasn't reset\")\n",
    "        \n",
    "        self.combined_observation += observation\n",
    "        \n",
    "        \n",
    "class StepPenaltyRewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, environment):\n",
    "        super().__init__(env)\n",
    "        # self.env = environment\n",
    "        \n",
    "        # self.action_space = env.action_space\n",
    "        # self.observation_space = env.observation_space\n",
    "        self._similarity_reward_weight = 1.0\n",
    "\n",
    "    \n",
    "#     def reset(self):\n",
    "#         self.env.reset()\n",
    "        \n",
    "        \n",
    "    def reward(self, reward):\n",
    "        print(\"Old reward: \", reward, \" New reward: \", -1 + self._similarity_reward_weight * reward)\n",
    "        reward = -1 + self._similarity_reward_weight * reward\n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def render(self, action, observation):\n",
    "        self.env.render(action, observation)\n",
    "        \n",
    "    \n",
    "    def final_reward(self, illustrate=False):\n",
    "        return self.env.final_reward(illustrate=illustrate)\n",
    "\n",
    "    \n",
    "    \n",
    "# TODO one more wrapper for GPU (observation, reward -> tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        \n",
    "        self.observation_size = env.observation_space.shape[0]\n",
    "        self.actions_cnt = env.action_space.n\n",
    "        \n",
    "        self._max_iter = 10\n",
    "        self._gamma = 0.99\n",
    "        self._final_reward_weight = 1.0\n",
    "  \n",
    "\n",
    "    def predict_action(self, state):\n",
    "        \"\"\"\n",
    "        Return action that should be done from input state according to current policy.\n",
    "        Args:\n",
    "            state: list of points - results of raycasting\n",
    "        return: \n",
    "            action: int\n",
    "        \"\"\"    \n",
    "        # some cool RL staff\n",
    "        return self.env.action_space.sample()\n",
    "    \n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Generate CAD model, reconstruct it and count the reward according   to MSE between original and reconstructed models and number of steps.\n",
    "        Args:\n",
    "            environment: Environment\n",
    "            max_iter: int - max number of iterations to stop (~15)\n",
    "            gamma: float - discounted factor\n",
    "            w: float - weight of mse to final episode reward\n",
    "        return: \n",
    "            episode_reward: float\n",
    "        \"\"\"    \n",
    "        \n",
    "        state = self.env.reset()\n",
    "        \n",
    "        episode_reward = 0.0\n",
    "        states = []\n",
    "        for t in range(self._max_iter):\n",
    "            action = self.predict_action(state)\n",
    "            state, reward, done, info = self.env.step(action)\n",
    "            print(\"REWARD: \", reward)\n",
    "            print()\n",
    "            states.append(state)\n",
    "            self.env.render(action, state)\n",
    "            episode_reward += reward * self._gamma ** t\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        final_reward = self.env.final_reward(illustrate=True)\n",
    "        print(\"Hausdorff reward: \", final_reward)\n",
    "        episode_reward += self._final_reward_weight / final_reward # QUESTION\n",
    "        return episode_reward, states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "env = CombiningObservationsWrapper(env)\n",
    "env = StepPenaltyRewardWrapper(env)\n",
    "\n",
    "agent = RandomAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to load materials from: FinalBaseMesh.mtl\n",
      "specified material (default)  not loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a1cc124ceb471ea7b5f664df329746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12a54832d694eee880c1c50c531bd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step reward: 0.275706 Comb reward: 0.451592 new reward: 0.175886 Len observation:  70077\n",
      "Old reward:  0.17588617686741076  New reward:  -0.8241138231325893\n",
      "REWARD:  -0.8241138231325893\n",
      "\n",
      "Step reward: 0.263543 Comb reward: 0.544912 new reward: 0.281369 Len observation:  101652\n",
      "Old reward:  0.2813688212927757  New reward:  -0.7186311787072244\n",
      "REWARD:  -0.7186311787072244\n",
      "\n",
      "Step reward: 0.357394 Comb reward: 0.799256 new reward: 0.441862 Len observation:  137841\n",
      "Old reward:  0.4418618913283454  New reward:  -0.5581381086716546\n",
      "REWARD:  -0.5581381086716546\n",
      "\n",
      "Step reward: 0.333722 Comb reward: 0.840672 new reward: 0.506950 Len observation:  170799\n",
      "Old reward:  0.5069504068032218  New reward:  -0.4930495931967782\n",
      "REWARD:  -0.4930495931967782\n",
      "\n",
      "Step reward: 0.295086 Comb reward: 0.890654 new reward: 0.595568 Len observation:  196483\n",
      "Old reward:  0.5955680935442986  New reward:  -0.4044319064557014\n",
      "REWARD:  -0.4044319064557014\n",
      "\n",
      "Step reward: 0.309988 Comb reward: 0.898994 new reward: 0.589006 Len observation:  232141\n",
      "Old reward:  0.5890060918271393  New reward:  -0.41099390817286074\n",
      "REWARD:  -0.41099390817286074\n",
      "\n",
      "Step reward: 0.347970 Comb reward: 0.907580 new reward: 0.559610 Len observation:  277146\n",
      "Old reward:  0.5596099595241015  New reward:  -0.44039004047589847\n",
      "REWARD:  -0.44039004047589847\n",
      "\n",
      "Step reward: 0.342287 Comb reward: 0.911403 new reward: 0.569116 Len observation:  321546\n",
      "Old reward:  0.5691156629461549  New reward:  -0.4308843370538451\n",
      "REWARD:  -0.4308843370538451\n",
      "\n",
      "Step reward: 0.342226 Comb reward: 0.916472 new reward: 0.574247 Len observation:  361823\n",
      "Old reward:  0.5742466985567685  New reward:  -0.42575330144323154\n",
      "REWARD:  -0.42575330144323154\n",
      "\n",
      "Step reward: 0.215953 Comb reward: 0.918312 new reward: 0.702359 Len observation:  388099\n",
      "Old reward:  0.7023590498385053  New reward:  -0.2976409501614947\n",
      "REWARD:  -0.2976409501614947\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d8d83c3f024b42b0b76925ba1d17dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hausdorff reward:  0.06039934073458476\n"
     ]
    }
   ],
   "source": [
    "reward, states = agent.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 512, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[-1].depth_map.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
