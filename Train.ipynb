{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import numpy as np\n",
    "import math, random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from geometry.model import Model, combine_observations, get_mesh\n",
    "from geometry.utils.visualisation import illustrate_points, illustrate_mesh, illustrate_voxels\n",
    "from geometry.voxel_grid import VoxelGrid\n",
    "\n",
    "from rl.environment import Environment, CombiningObservationsWrapper\n",
    "from rl.environment import StepPenaltyRewardWrapper, DepthMapWrapper\n",
    "from rl.environment import VoxelGridWrapper, VoxelWrapper\n",
    "from rl.environment import FrameStackWrapper, ActionMaskWrapper\n",
    "from rl.environment import MeshReconstructionWrapper\n",
    "from rl.validation import validate\n",
    "from rl.utils import build_epsilon_func, plot\n",
    "\n",
    "\n",
    "from rl.dqn import CnnDQN, CnnDQNA, VoxelDQN\n",
    "from rl.agent import DQNAgent, DDQNAgent\n",
    "from rl.replay_buffer import DiskReplayBuffer, ReplayBuffer\n",
    "\n",
    "\n",
    "# !conda install -c conda-forge pyembree\n",
    "# !conda install -c conda-forge igl\n",
    "# !pip install Cython\n",
    "# !pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "experiment_save_path = \"./models/abc-vddqn-final_rec_only/\"\n",
    "\n",
    "train_dataset_path = \"./data/1kabc/simple/train/\"\n",
    "val_dataset_path = \"./data/1kabc/simple/val/\"\n",
    "number_of_view_points = 100\n",
    "\n",
    "num_stack = 4\n",
    "reconstruction_depth = 7\n",
    "grid_size = 64\n",
    "raycast_resolution = 1024\n",
    "\n",
    "optim_name = \"Adam\"\n",
    "learning_rate = 0.0004\n",
    "weight_decay = 0.01\n",
    "buffer_capacity = 100000\n",
    "epsilon_decay = 10000\n",
    "batch_size = 256\n",
    "start_frame = 0\n",
    "num_frames = 150000\n",
    "\n",
    "log_interval = 100\n",
    "save_interval = 500\n",
    "val_interval = 1000\n",
    "train_interval = 10\n",
    "max_novp = 50\n",
    "\n",
    "use_depth_observations = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = Environment(models_path=train_dataset_path,\n",
    "                  image_size=raycast_resolution,\n",
    "                  number_of_view_points=number_of_view_points)\n",
    "\n",
    "if use_depth_observations:\n",
    "    env = CombiningObservationsWrapper(env)\n",
    "    env = StepPenaltyRewardWrapper(env, weight=1.0)\n",
    "    env = DepthMapWrapper(env)\n",
    "else:\n",
    "    env = MeshReconstructionWrapper(env, reconstruction_depth=7,\n",
    "                                    do_step_reconstruction=False, \n",
    "                                    scale_factor=8)\n",
    "\n",
    "    env = VoxelGridWrapper(env, grid_size=grid_size)\n",
    "    env = CombiningObservationsWrapper(env)\n",
    "    env = VoxelWrapper(env, occlusion_reward=False)\n",
    "    env = StepPenaltyRewardWrapper(env, weight=1.0)\n",
    "    env = FrameStackWrapper(env, num_stack=num_stack, lz4_compress=False)\n",
    "    env = ActionMaskWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prev_ckpt = \"./models/abc-vddqn-final_rec_only/last-3000.pt\"\n",
    "\n",
    "\n",
    "agent = DDQNAgent(env.observation_space.shape, env.action_space.n, prev_ckpt=prev_ckpt,\n",
    "                  device=device, learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "replay_buffer = DiskReplayBuffer(capacity=buffer_capacity,\n",
    "                                 overwrite=True,\n",
    "                                 location=\"buffer_voxels/\",\n",
    "                                 num_actions=env.action_space.n,\n",
    "                                 observation_dtype=env.observation_space.dtype,\n",
    "                                 observation_shape=env.observation_space.shape)\n",
    "\n",
    "epsilon_by_frame = build_epsilon_func(epsilon_decay=epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(experiment_save_path):\n",
    "    os.makedirs(experiment_save_path)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "losses, all_rewards, all_nofs = [], [], []\n",
    "episode_reward = 0\n",
    "nof_vp = 0\n",
    "best_metric = number_of_view_points\n",
    "\n",
    "state, _, mask = env.reset()\n",
    "for frame_idx in range(start_frame + 1, num_frames + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = agent.act(state, mask, epsilon)\n",
    "\n",
    "    next_state, reward, done, _, mask = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done, mask)\n",
    "\n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    nof_vp += 1\n",
    "\n",
    "    if done or nof_vp > max_novp:\n",
    "        final_reward = env.final_reward()\n",
    "        episode_reward += final_reward\n",
    "        print(\"Frame: \", frame_idx, \"Number of View Points: \", nof_vp, final_reward)\n",
    "        print()\n",
    "\n",
    "        state, _, mask = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        all_nofs.append(nof_vp)\n",
    "        episode_reward = 0\n",
    "        nof_vp = 0\n",
    "        \n",
    "    if frame_idx % train_interval == 0 and frame_idx > batch_size:\n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "        state_, action_, reward_, next_state_, done_, mask_ = batch\n",
    "        loss = agent.compute_td_loss(state_, action_, reward_, next_state_, done_, mask_, frame_idx)\n",
    "        losses.append(loss)\n",
    "\n",
    "    if frame_idx % log_interval == 0:\n",
    "        save_path = os.path.join(experiment_save_path, 'loss.png')\n",
    "        plot(save_path, frame_idx, all_rewards, all_nofs, losses)\n",
    "\n",
    "    if frame_idx % save_interval ==  0:\n",
    "        for f in glob.glob(os.path.join(experiment_save_path, \"last-*.pt\")): os.remove(f)\n",
    "        save_path = os.path.join(experiment_save_path,\n",
    "                                 'last-{}.pt'.format(frame_idx))\n",
    "        torch.save(agent.model, save_path)\n",
    "\n",
    "    if frame_idx % val_interval == 0:\n",
    "        reward, hausdorff, novp = validate(agent, models_path=val_dataset_path)\n",
    "        print (\"Validation metrics: \", reward, hausdorff, novp)\n",
    "        if novp < best_metric:\n",
    "            best_metric = novp\n",
    "            save_path = os.path.join(experiment_save_path,\n",
    "                                 'best-{}-{:.2f}.pt'.format(frame_idx, best_metric))\n",
    "            torch.save(agent.model, save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
